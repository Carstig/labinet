{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "#import numpy as np\n",
    "#import tensorflow as tf\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Import utilites\n",
    "#from utils import label_map_util\n",
    "#from utils import visualization_utils as vis_util\n",
    "\n",
    "try:\n",
    "    from labinet.io_util import load_label_map\n",
    "    from labinet.io_util import load_model\n",
    "#    import labinet.object_detect\n",
    "except ImportError:\n",
    "    # This part is only required to run the notebook\n",
    "    # directory when the module itself is not installed.\n",
    "    #\n",
    "    # If you have the module installed, just use \"import labinet...\"\n",
    "    import os\n",
    "    import inspect\n",
    "    # the .travis.yml is coded so that we execute tests from within test subdir. Relative to 'test' the .py is found in ../source/dev\n",
    "    cmd_subfolder = os.path.realpath(os.path.abspath(os.path.join(os.path.split(inspect.getfile(inspect.currentframe()))[0], \"..\")))\n",
    "    if cmd_subfolder not in sys.path:\n",
    "        sys.path.insert(0, cmd_subfolder)\n",
    "    from labinet.io_util import load_label_map\n",
    "    from labinet.io_util import load_model\n",
    " #   import labinet.object_detect\n",
    "\n",
    "%aimport labinet.io_util\n",
    "%aimport labinet.object_detect\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## change path, model name etc to your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'inference_graph'   # the result from Step 6 Export Inference Graph\n",
    "IMAGE_PATH = 'images'\n",
    "IMAGE_NAME = '01-20190414173244-01.jpg'   # cmdline arg\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 8)\n",
    "CWD_PATH = os.path.join(os.getcwd(),'..')  # should become gitbase\n",
    "NUM_CLASSES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "PATH_TO_MODEL = os.path.join(CWD_PATH, MODEL_NAME, 'frozen_inference_graph.pb')\n",
    "# label map\n",
    "LABEL_MAP = os.path.join(CWD_PATH, 'data', 'object-detection.pbtxt')\n",
    "# path to image\n",
    "PATH_TO_IMAGE = os.path.join(CWD_PATH, IMAGE_PATH, IMAGE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load (frozen) Model into Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = load_model(PATH_TO_MODEL)\n",
    "#sess = tf.Session(graph=detection_graph)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories, category_index = load_label_map(LABEL_MAP, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference : Object Detection \n",
    "_load the image and run on it the object detection_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "image =  Image.open(PATH_TO_IMAGE)\n",
    "#imshow(np.asarray(image))\n",
    "\n",
    "# inference\n",
    "output_dict = labinet.object_detect.run_inference_for_single_image(image, detection_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-20190414173244-01.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%aimport labinet.object_detect \n",
    "\n",
    "image_with_boxes = labinet.object_detect.visualize_boxes_after_detection(image, output_dict, category_index)\n",
    "# All the results have been drawn on image. Now display the image.\n",
    "plt.figure(figsize=IMAGE_SIZE)\n",
    "#plt.imshow(image_with_boxes)\n",
    "print(IMAGE_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = output_dict['detection_boxes']\n",
    "scores = output_dict['detection_scores']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxes_to_use(detection_boxes, detection_scores, min_score_threshold=0.8):\n",
    "    boxes = detection_boxes\n",
    "    scores = detection_scores\n",
    "    #print(output_dict['detection_boxes'])\n",
    "    num_boxes = boxes.shape[0]    \n",
    "    boxes_to_use = []\n",
    "    for i in range(num_boxes):\n",
    "        if scores is None or scores[i] > min_score_threshold:\n",
    "            box = boxes[i]\n",
    "            boxes_to_use.append(box)       \n",
    "            #score = int(scores[i] * 100)\n",
    "            #print(f\"Use box[{i}]={boxes[i]}. (score is {score}%)\")\n",
    "    return boxes_to_use        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_to_use = get_boxes_to_use(boxes, scores)\n",
    "boxes_to_use[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_coordinates(box, image_size):\n",
    "    '''\n",
    "    return box coordinates resized to image_size\n",
    "    left, right, top, bottom aka xmin, xmax, ymin, ymax\n",
    "    '''\n",
    "    (ymin, xmin, ymax, xmax) = box\n",
    "    im_width = image_size[0]\n",
    "    im_height = image_size[1]\n",
    "    (left, right, top, bottom) = (int(xmin * im_width), int(xmax * im_width), int(ymin * im_height), int(ymax * im_height))\n",
    "    box = { 'xmin': left, 'xmax': right, 'ymin': top, 'ymax': bottom }\n",
    "    return box\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_normed = []\n",
    "for box in boxes_to_use:\n",
    "    box_normed = get_normalized_coordinates(box, image.size)\n",
    "    boxes_normed.append(box_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_to_labelimg_xml(filename, image_size, boxes, label='dog', path=None, ):\n",
    "    # todo: change xmin, xmax... to array of 'boxes'\n",
    "    root = ET.Element('annotation')\n",
    "    folder = ET.SubElement(root, 'folder')\n",
    "    folder.text = 'images'\n",
    "    fname = ET.SubElement(root, 'filename')\n",
    "    fname.text = filename\n",
    "    \n",
    "    source = ET.SubElement(root, 'source')\n",
    "    database = ET.SubElement(source, 'database')\n",
    "    database.text = 'Unknown'\n",
    "    \n",
    "    size = ET.SubElement(root, 'size')\n",
    "    width = ET.SubElement(size, 'width')\n",
    "    width.text = str(image_size[0])\n",
    "    height = ET.SubElement(size, 'height')\n",
    "    height.text = str(image_size[1])\n",
    "    depth = ET.SubElement(size, 'depth')\n",
    "    depth.text = '3'\n",
    "    \n",
    "    segmented = ET.SubElement(root, 'segmented')\n",
    "    segmented.text = '0'\n",
    "    \n",
    "    ### 1 box. each box becomes 'object'\n",
    "    for box in boxes:\n",
    "        obj = ET.SubElement(root, 'object')\n",
    "        name = ET.SubElement(obj, 'name')\n",
    "        name.text = label\n",
    "        pose = ET.SubElement(obj, 'pose')\n",
    "        pose.text = 'Unspecified'\n",
    "        truncated = ET.SubElement(obj, 'truncated')\n",
    "        truncated.text = '0'\n",
    "        difficult = ET.SubElement(obj, 'difficult')\n",
    "        difficult.text = '0'\n",
    "        bndbox = ET.SubElement(obj, 'bndbox')\n",
    "        xminx = ET.SubElement(bndbox, 'xmin')\n",
    "        xminx.text = str(box['xmin'])\n",
    "        xmaxx = ET.SubElement(bndbox, 'xmax')\n",
    "        xmaxx.text = str(box['xmax'])\n",
    "        yminx = ET.SubElement(bndbox, 'ymin')\n",
    "        yminx.text = str(box['ymin'])\n",
    "        ymaxx = ET.SubElement(bndbox, 'ymax')\n",
    "        ymaxx.text = str(box['ymax'])\n",
    "\n",
    "    tree = ET.ElementTree(root)\n",
    "    return tree\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml = box_to_labelimg_xml('file.jpg', (640,480), boxes_normed)\n",
    "ET.dump(xml)\n",
    "#xml.tostring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
