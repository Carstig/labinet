{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "try:\n",
    "    from labinet.io_util import load_label_map\n",
    "    from labinet.io_util import load_model\n",
    "    import labinet.object_detect\n",
    "    import labinet.box\n",
    "except ImportError:\n",
    "    # This part is only required to run the notebook\n",
    "    # directory when the module itself is not installed.\n",
    "    #\n",
    "    # If you have the module installed, just use \"import labinet...\"\n",
    "    import os\n",
    "    import inspect\n",
    "    # the .travis.yml is coded so that we execute tests from within test subdir. Relative to 'test' the .py is found in ../source/dev\n",
    "    cmd_subfolder = os.path.realpath(os.path.abspath(os.path.join(os.path.split(inspect.getfile(inspect.currentframe()))[0], \"..\")))\n",
    "    if cmd_subfolder not in sys.path:\n",
    "        sys.path.insert(0, cmd_subfolder)\n",
    "    from labinet.io_util import load_label_map\n",
    "    from labinet.io_util import load_model\n",
    "    import labinet.object_detect\n",
    "    import labinet.box\n",
    "\n",
    "%aimport labinet.io_util\n",
    "%aimport labinet.object_detect\n",
    "%aimport labinet.box\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## change path, model name etc to your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'inference_graph'   # the result from Step 6 Export Inference Graph\n",
    "IMAGE_PATH = 'images'\n",
    "IMAGE_NAME = '01-20190414173244-01.jpg'   # cmdline arg\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 8)\n",
    "CWD_PATH = os.path.join(os.getcwd(),'..')  # should become gitbase\n",
    "NUM_CLASSES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "PATH_TO_MODEL = os.path.join(CWD_PATH, MODEL_NAME, 'frozen_inference_graph.pb')\n",
    "# label map\n",
    "LABEL_MAP = os.path.join(CWD_PATH, 'data', 'object-detection.pbtxt')\n",
    "# path to image\n",
    "PATH_TO_IMAGE = os.path.join(CWD_PATH, IMAGE_PATH, IMAGE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load (frozen) Model into Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = load_model(PATH_TO_MODEL)\n",
    "#sess = tf.Session(graph=detection_graph)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories, category_index = load_label_map(LABEL_MAP, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference : Object Detection \n",
    "_load the image and run on it the object detection_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "image =  Image.open(PATH_TO_IMAGE)\n",
    "#imshow(np.asarray(image))\n",
    "\n",
    "# inference\n",
    "output_dict = labinet.object_detect.run_inference_for_single_image(image, detection_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-20190414173244-01.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_with_boxes = labinet.object_detect.visualize_boxes_after_detection(image, output_dict, category_index)\n",
    "# All the results have been drawn on image. Now display the image.\n",
    "plt.figure(figsize=IMAGE_SIZE)\n",
    "#plt.imshow(image_with_boxes)\n",
    "print(IMAGE_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Result as XML\n",
    "_use the xml file to laod image in labelImg and check correct boxing_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = output_dict['detection_boxes']\n",
    "scores = output_dict['detection_scores']\n",
    "boxes_to_use = labinet.object_detect.get_boxes_to_use(boxes, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need the box' coordinates relative to the image size\n",
    "boxes_normed = []\n",
    "for box in boxes_to_use:\n",
    "    box_normed = labinet.box.get_normalized_coordinates(box, image.size)\n",
    "    boxes_normed.append(box_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<annotation><folder>images</folder><filename>01-20190414173244-01.jpg</filename><path>C:\\Users\\Carsten\\Documents\\python\\object_detection\\labinet\\notebook\\..\\images\\01-20190414173244-01.jpg</path><source><database>Unknown</database></source><size><width>480</width><height>640</height><depth>3</depth></size><segmented>0</segmented><object><name>dog</name><pose>Unspecified</pose><truncated>0</truncated><difficult>0</difficult><bndbox><xmin>124</xmin><xmax>307</xmax><ymin>426</ymin><ymax>591</ymax></bndbox></object><object><name>dog</name><pose>Unspecified</pose><truncated>0</truncated><difficult>0</difficult><bndbox><xmin>157</xmin><xmax>366</xmax><ymin>456</ymin><ymax>585</ymax></bndbox></object><object><name>dog</name><pose>Unspecified</pose><truncated>0</truncated><difficult>0</difficult><bndbox><xmin>214</xmin><xmax>381</xmax><ymin>463</ymin><ymax>575</ymax></bndbox></object></annotation>\n"
     ]
    }
   ],
   "source": [
    "%aimport labinet.box\n",
    "\n",
    "xml = labinet.box.box_to_labelimg_xml(IMAGE_NAME, image.size, boxes_normed, imagepath=PATH_TO_IMAGE)\n",
    "ET.dump(xml)\n",
    "xmlfname = PATH_TO_IMAGE[:-4]+\".xml\"\n",
    "xml.write(xmlfname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do inference an all new files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_IMAGE_PATH = os.path.join(CWD_PATH, 'new_images')\n",
    "files = os.listdir(NEW_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference on: 01-20190414173201-00.jpg\n",
      "found 0 objects\n",
      "inference on: 01-20190414173202-00.jpg\n",
      "found 0 objects\n",
      "inference on: 01-20190414173205-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173206-00.jpg\n",
      "found 0 objects\n",
      "inference on: 01-20190414173207-00.jpg\n",
      "found 0 objects\n",
      "inference on: 01-20190414173208-00.jpg\n",
      "found 0 objects\n",
      "inference on: 01-20190414173230-00.jpg\n",
      "found 2 objects\n",
      "inference on: 01-20190414173231-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173232-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173233-00.jpg\n",
      "found 2 objects\n",
      "inference on: 01-20190414173234-00.jpg\n",
      "found 0 objects\n",
      "inference on: 01-20190414173236-00.jpg\n",
      "found 2 objects\n",
      "inference on: 01-20190414173237-00.jpg\n",
      "found 2 objects\n",
      "inference on: 01-20190414173238-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173240-00.jpg\n",
      "found 2 objects\n",
      "inference on: 01-20190414173241-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173242-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173243-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173244-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173245-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173246-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173247-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173248-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173249-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173250-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173255-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173311-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173312-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173314-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173315-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173316-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173317-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173336-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173337-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173340-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173344-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173350-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173359-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173412-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173416-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173418-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173419-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173421-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173422-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173424-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173425-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173427-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173428-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173429-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173431-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173432-00.jpg\n",
      "found 0 objects\n",
      "inference on: 01-20190414173433-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173435-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173445-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173522-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173524-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173525-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173527-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173528-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173529-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173530-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173531-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173537-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173538-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173539-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173540-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173541-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173542-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173543-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173545-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173546-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173547-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173626-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173627-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173628-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173630-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173631-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173633-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173634-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173707-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173709-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173710-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173712-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173727-00.jpg\n",
      "found 0 objects\n",
      "inference on: 01-20190414173729-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173730-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173740-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173742-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173743-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173744-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173747-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173749-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173751-00.jpg\n",
      "found 1 objects\n",
      "inference on: 01-20190414173757-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414173959-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174000-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174001-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174003-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174004-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174006-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174008-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174009-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174013-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174015-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174016-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174022-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174036-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174043-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174045-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174049-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174104-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174105-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174108-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174113-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174114-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174115-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174123-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174124-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174125-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174126-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174127-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174128-00.jpg\n",
      "found 2 objects\n",
      "inference on: 02-20190414174130-00.jpg\n",
      "found 2 objects\n",
      "inference on: 02-20190414174132-00.jpg\n",
      "found 2 objects\n",
      "inference on: 02-20190414174135-00.jpg\n",
      "found 2 objects\n",
      "inference on: 02-20190414174137-00.jpg\n",
      "found 2 objects\n",
      "inference on: 02-20190414174138-00.jpg\n",
      "found 2 objects\n",
      "inference on: 02-20190414174140-00.jpg\n",
      "found 2 objects\n",
      "inference on: 02-20190414174146-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174147-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174153-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174154-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174155-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174156-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174158-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174201-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174202-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174204-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174206-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174207-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174209-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174211-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174212-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174213-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174214-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174215-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174216-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174217-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174218-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174219-00.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 0 objects\n",
      "inference on: 02-20190414174220-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174221-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174222-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174247-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174248-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174249-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174255-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174300-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174301-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174302-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174308-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174346-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174352-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174353-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174355-00.jpg\n",
      "found 2 objects\n",
      "inference on: 02-20190414174358-00.jpg\n",
      "found 2 objects\n",
      "inference on: 02-20190414174400-00.jpg\n",
      "found 2 objects\n",
      "inference on: 02-20190414174403-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174405-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174406-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174431-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174432-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174434-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174435-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174436-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174437-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174438-00.jpg\n",
      "found 2 objects\n",
      "inference on: 02-20190414174439-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174440-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174441-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174442-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174443-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174444-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174445-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174446-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174447-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174448-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174449-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174450-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174453-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174454-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174455-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174456-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174457-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174458-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174459-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174500-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174501-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174502-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174503-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174529-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174530-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174534-00.jpg\n",
      "found 1 objects\n",
      "inference on: 02-20190414174535-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174536-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174537-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174538-00.jpg\n",
      "found 0 objects\n",
      "inference on: 02-20190414174539-00.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-d76ebc2a419e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'inference on: {fname}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0moutput_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabinet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_detect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_inference_for_single_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetection_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mboxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'detection_boxes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'detection_scores'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\python\\object_detection\\labinet\\labinet\\object_detect.py\u001b[0m in \u001b[0;36mrun_inference_for_single_image\u001b[1;34m(image, graph)\u001b[0m\n\u001b[0;32m     47\u001b[0m       \u001b[1;31m# Run inference\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m       output_dict = sess.run(tensor_dict,\n\u001b[1;32m---> 49\u001b[1;33m                              feed_dict={image_tensor: image_np_exp})\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m       \u001b[1;31m# all outputs are float32 numpy arrays, so convert types as appropriate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for fname in files:\n",
    "    if fname.endswith('jpg'):\n",
    "        image_file = os.path.join(NEW_IMAGE_PATH, fname)\n",
    "        print(f'inference on: {fname}')\n",
    "        image =  Image.open(image_file)\n",
    "        output_dict = labinet.object_detect.run_inference_for_single_image(image, detection_graph)\n",
    "        boxes = output_dict['detection_boxes']\n",
    "        scores = output_dict['detection_scores']\n",
    "        boxes_to_use = labinet.object_detect.get_boxes_to_use(boxes, scores)\n",
    "        boxes_normed = []\n",
    "        print(f'found {len(boxes_to_use)} objects')\n",
    "        for box in boxes_to_use:\n",
    "            box_normed = labinet.box.get_normalized_coordinates(box, image.size)\n",
    "            boxes_normed.append(box_normed)\n",
    "\n",
    "        xml = labinet.box.box_to_labelimg_xml(fname, image.size, boxes_normed, imagepath=image_file)\n",
    "        xmlfname = image_file[:-4]+\".xml\"\n",
    "        xml.write(xmlfname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
