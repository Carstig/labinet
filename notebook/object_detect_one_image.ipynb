{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Import utilites\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## change path, model name etc to your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'inference_graph'   # the result from Step 6 Export Inference Graph\n",
    "IMAGE_PATH = 'images'\n",
    "IMAGE_NAME = '01-20190414173244-01.jpg'   # cmdline arg\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 8)\n",
    "CWD_PATH = os.path.join(os.getcwd(),'..')  # should become gitbase\n",
    "NUM_CLASSES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "PATH_TO_MODEL = os.path.join(CWD_PATH, MODEL_NAME, 'frozen_inference_graph.pb')\n",
    "# label map\n",
    "LABEL_MAP = os.path.join(CWD_PATH, 'data', 'object-detection.pbtxt')\n",
    "# path to image\n",
    "PATH_TO_IMAGE = os.path.join(CWD_PATH, IMAGE_PATH, IMAGE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label_map(path_to_labels, num_classes):\n",
    "    label_map = label_map_util.load_labelmap(path_to_labels)\n",
    "    categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=num_classes, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    return categories, category_index\n",
    "\n",
    "# from https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb\n",
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "# from https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb\n",
    "def run_inference_for_single_image(image, graph):\n",
    "  with graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "      # Get handles to input and output tensors\n",
    "      ops = tf.get_default_graph().get_operations()\n",
    "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "      tensor_dict = {}\n",
    "      for key in [\n",
    "          'num_detections', 'detection_boxes', 'detection_scores',\n",
    "          'detection_classes', 'detection_masks'\n",
    "      ]:\n",
    "        tensor_name = key + ':0'\n",
    "        if tensor_name in all_tensor_names:\n",
    "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "              tensor_name)\n",
    "      if 'detection_masks' in tensor_dict:\n",
    "        # The following processing is only for single image\n",
    "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "            detection_masks, detection_boxes, image.shape[1], image.shape[2])\n",
    "        detection_masks_reframed = tf.cast(\n",
    "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "        # Follow the convention by adding back the batch dimension\n",
    "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "            detection_masks_reframed, 0)\n",
    "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "      # Run inference\n",
    "      output_dict = sess.run(tensor_dict,\n",
    "                             feed_dict={image_tensor: image})\n",
    "\n",
    "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "      output_dict['detection_classes'] = output_dict[\n",
    "          'detection_classes'][0].astype(np.int64)\n",
    "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "      if 'detection_masks' in output_dict:\n",
    "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "  return output_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories, category_index = load_label_map(LABEL_MAP, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load (frozen) Model into Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_MODEL, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "    sess = tf.Session(graph=detection_graph)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "image =  Image.open(PATH_TO_IMAGE)\n",
    "#imshow(np.asarray(image))\n",
    "# reshape image to [1, None, None, 3] so all pixels are in one column\n",
    "image_np = load_image_into_numpy_array(image)\n",
    "image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "## detect!\n",
    "#(boxes, scores, classes, num) = sess.run([detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "#    feed_dict={image_tensor: image_expanded})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = run_inference_for_single_image(image_np_expanded, detection_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-20190414173244-01.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np,\n",
    "     output_dict['detection_boxes'],\n",
    "      output_dict['detection_classes'],\n",
    "      output_dict['detection_scores'],\n",
    "      category_index,\n",
    "      instance_masks=output_dict.get('detection_masks'),\n",
    "      use_normalized_coordinates=True,\n",
    "      line_thickness=4 )\n",
    "\n",
    "# All the results have been drawn on image. Now display the image.\n",
    "plt.figure(figsize=IMAGE_SIZE)\n",
    "plt.imshow(image_np)\n",
    "print(IMAGE_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = output_dict['detection_boxes']\n",
    "scores = output_dict['detection_scores']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxes_to_use(detection_boxes, detection_scores, min_score_threshold=0.8):\n",
    "    boxes = detection_boxes\n",
    "    scores = detection_scores\n",
    "    #print(output_dict['detection_boxes'])\n",
    "    num_boxes = boxes.shape[0]    \n",
    "    boxes_to_use = []\n",
    "    for i in range(num_boxes):\n",
    "        if scores is None or scores[i] > min_score_threshold:\n",
    "            box = boxes[i]\n",
    "            boxes_to_use.append(box)       \n",
    "            #score = int(scores[i] * 100)\n",
    "            #print(f\"Use box[{i}]={boxes[i]}. (score is {score}%)\")\n",
    "    return boxes_to_use        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_to_use = get_boxes_to_use(boxes, scores)\n",
    "boxes_to_use[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_coordinates(box, image_size):\n",
    "    '''\n",
    "    return box coordinates resized to image_size\n",
    "    left, right, top, bottom aka xmin, xmax, ymin, ymax\n",
    "    '''\n",
    "    (ymin, xmin, ymax, xmax) = box\n",
    "    im_width = image_size[0]\n",
    "    im_height = image_size[1]\n",
    "    (left, right, top, bottom) = (int(xmin * im_width), int(xmax * im_width), int(ymin * im_height), int(ymax * im_height))\n",
    "    box = { 'xmin': left, 'xmax': right, 'ymin': top, 'ymax': bottom }\n",
    "    return box\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = get_normalized_coordinates(boxes_to_use[0], image.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_to_labelimg_xml(filename, image_size, boxes, label='dog', path=None, ):\n",
    "    # todo: change xmin, xmax... to array of 'boxes'\n",
    "    root = ET.Element('annotation')\n",
    "    folder = ET.SubElement(root, 'folder')\n",
    "    folder.text = 'images'\n",
    "    fname = ET.SubElement(root, 'filename')\n",
    "    fname.text = filename\n",
    "    \n",
    "    source = ET.SubElement(root, 'source')\n",
    "    database = ET.SubElement(source, 'database')\n",
    "    database.text = 'Unknown'\n",
    "    \n",
    "    size = ET.SubElement(root, 'size')\n",
    "    width = ET.SubElement(size, 'width')\n",
    "    width.text = str(image_size[0])\n",
    "    height = ET.SubElement(size, 'height')\n",
    "    height.text = str(image_size[1])\n",
    "    depth = ET.SubElement(size, 'depth')\n",
    "    depth.text = '3'\n",
    "    \n",
    "    segmented = ET.SubElement(root, 'segmented')\n",
    "    segmented.text = '0'\n",
    "    \n",
    "    ### 1 box. each box becomes 'object'\n",
    "    for box in boxes:\n",
    "        obj = ET.SubElement(root, 'object')\n",
    "        name = ET.SubElement(obj, 'name')\n",
    "        name.text = label\n",
    "        pose = ET.SubElement(obj, 'pose')\n",
    "        pose.text = 'Unspecified'\n",
    "        truncated = ET.SubElement(obj, 'truncated')\n",
    "        truncated.text = '0'\n",
    "        difficult = ET.SubElement(obj, 'difficult')\n",
    "        difficult.text = '0'\n",
    "        bndbox = ET.SubElement(obj, 'bndbox')\n",
    "        xminx = ET.SubElement(bndbox, 'xmin')\n",
    "        xminx.text = str(box['xmin'])\n",
    "        xmaxx = ET.SubElement(bndbox, 'xmax')\n",
    "        xmaxx.text = str(box['xmax'])\n",
    "        yminx = ET.SubElement(bndbox, 'ymin')\n",
    "        yminx.text = str(box['ymin'])\n",
    "        ymaxx = ET.SubElement(bndbox, 'ymax')\n",
    "        ymaxx.text = str(box['ymax'])\n",
    "\n",
    "    tree = ET.ElementTree(root)\n",
    "    return tree\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = []\n",
    "boxes.append(box)\n",
    "boxes.append(box)\n",
    "xml = box_to_labelimg_xml('file.jpg', (640,480), boxes)\n",
    "ET.dump(xml)\n",
    "#xml.tostring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
